{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1099ed7e-594f-4183-b124-124960ac7098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of predictions:\n",
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- traffic_label: double (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy:  0.6099\n",
      "F1 Score:  0.6022\n",
      "Precision: 0.6189\n",
      "Recall:    0.6099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[10223. 11506.]\n",
      " [ 5474. 16329.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "# Start Spark session\n",
    "spark = SparkSession.builder.appName(\"EvaluateTrafficModel\").getOrCreate()\n",
    "\n",
    "# Load predictions from HDFS (CSV format)\n",
    "predictions = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\n",
    "    \"hdfs://localhost:9000/user/hdoop/toronto_traffic/output/final_predictions_csv\"\n",
    ")\n",
    "\n",
    "# Print schema to confirm the structure\n",
    "print(\"Schema of predictions:\")\n",
    "predictions.printSchema()\n",
    "\n",
    "# Cast traffic_label and prediction columns to double\n",
    "predictions = predictions.withColumn(\"traffic_label\", predictions[\"traffic_label\"].cast(\"double\"))\n",
    "predictions = predictions.withColumn(\"prediction\", predictions[\"prediction\"].cast(\"double\"))\n",
    "\n",
    "# Create an evaluator object\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"traffic_label\", predictionCol=\"prediction\")\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy = evaluator.setMetricName(\"accuracy\").evaluate(predictions)\n",
    "f1 = evaluator.setMetricName(\"f1\").evaluate(predictions)\n",
    "precision = evaluator.setMetricName(\"weightedPrecision\").evaluate(predictions)\n",
    "recall = evaluator.setMetricName(\"weightedRecall\").evaluate(predictions)\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "\n",
    "# Compute the confusion matrix using RDD-based MulticlassMetrics\n",
    "pred_rdd = predictions.select(\"prediction\", \"traffic_label\").rdd.map(lambda row: (row[\"prediction\"], row[\"traffic_label\"]))\n",
    "metrics = MulticlassMetrics(pred_rdd)\n",
    "conf_matrix = metrics.confusionMatrix().toArray()\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark (PySpark)",
   "language": "python",
   "name": "spark-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
